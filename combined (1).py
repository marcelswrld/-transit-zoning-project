# -*- coding: utf-8 -*-
"""Combined.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mLHNGl1ZIFT5VxOiS_DksYi_hs7sB5ht
"""

import partridge as ptg
import pandas as pd
import numpy as np
import geopandas as gpd
from shapely.geometry import Point
from shapely.strtree import STRtree
from datetime import datetime
import os

"""![flowchart](https://i.postimg.cc/Dy3gLM6f/image.png)

# Place file paths here

Replace these file paths with the ones you are using. Each file path should be a zipped or unzipped GTFS file.
"""

gtfs_path_2024 = ['/Volumes/One_Touch/Transit_Job/GTFS_Only/ACT_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/BART_Oct2024',
                  '/Volumes/One_Touch/Transit_Job/GTFS_Only/BBB_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/LADOT_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetro_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetroRail_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/MTS_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/MUNI_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/OCTA_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/Omni_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/Sac_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/VTA_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/CC_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/NCTD_Oct2024',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/Caltrain_Oct2024', '/Volumes/One_Touch/Transit_Job/GTFS_Only/SFBayFerry_Oct2024']

gtfs_path_2020 = ['/Volumes/One_Touch/Transit_Job/GTFS_Only/ACT_Aug2019', '/Volumes/One_Touch/Transit_Job/GTFS_Only/BART_Jan2020',
                  '/Volumes/One_Touch/Transit_Job/GTFS_Only/BBB_Jan2020', '/Volumes/One_Touch/Transit_Job/GTFS_Only/CC_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetro_Jan2020', '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetroRail_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/MTS_Jan2020', '/Volumes/One_Touch/Transit_Job/GTFS_Only/MUNI_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/OCTA_Jan2020', '/Volumes/One_Touch/Transit_Job/GTFS_Only/Omni_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/Sac_Dec2019', '/Volumes/One_Touch/Transit_Job/GTFS_Only/VTA_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/NCTD_Jan2020', '/Volumes/One_Touch/Transit_Job/GTFS_Only/Caltrain_Jan2020',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/SFBayFerry_Jan2020']

gtfs_path_2014 = ['/Volumes/One_Touch/Transit_Job/GTFS_Only/ACT_Nov2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/BART_Dec2014',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/BBB_Aug2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/LADOT_Dec2014',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetro_Oct2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/LAMetroRail_May2016',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/MTS_Oct2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/MUNI_Oct2014',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/OCTA_Oct2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/Omni_Sept2014',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/Sac_Nov2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/VTA_Oct2014',
                 '/Volumes/One_Touch/Transit_Job/GTFS_Only/NCTD_Oct2014', '/Volumes/One_Touch/Transit_Job/GTFS_Only/Caltrain_Oct2014',
                      '/Volumes/One_Touch/Transit_Job/GTFS_Only/SFBayFerry_Oct2014']

"""# Maximal/Minimal Toggle

If "maximal" is set to True, the maximal interpretation will be automatically applied throughout the notebook. If it is set to False, the minimal interpretation will be applied.
"""

maximal = True

"""# Step #1: Loading GTFS

This step takes multiple GTFS files and combines them into one dataset.
"""

class GTFSFeed:
    """
    A custom GTFS object for handling concatenated GTFS tables.
    """
    def __init__(self, routes, trips, stop_times, stops):
        self.routes = routes
        self.trips = trips
        self.stop_times = stop_times
        self.stops = stops

def load_and_combine_gtfs(gtfs_paths):
    """
    Loads multiple GTFS files and combine them into a single object.
    """
    # Initialize empty DataFrames for each GTFS table
    combined_routes = pd.DataFrame()
    combined_trips = pd.DataFrame()
    combined_stop_times = pd.DataFrame()
    combined_stops = pd.DataFrame()

    # Loop through each GTFS file and append data
    for path in gtfs_paths:
        prefix = path.stem[:10] if hasattr(path, 'stem') else os.path.splitext(os.path.basename(path))[0]
        feed = ptg.load_feed(path)

       # Make sure ID columns are strings before applying prefixes
        feed.routes['route_id'] = feed.routes['route_id'].astype(str)
        feed.trips['route_id'] = feed.trips['route_id'].astype(str)
        feed.trips['trip_id'] = feed.trips['trip_id'].astype(str)
        feed.stop_times['trip_id'] = feed.stop_times['trip_id'].astype(str)
        feed.stop_times['stop_id'] = feed.stop_times['stop_id'].astype(str)
        feed.stops['stop_id'] = feed.stops['stop_id'].astype(str)

        # Apply prefix to IDs (otherwise routes with same numbers will get mixed up)
        feed.routes['prefixed_route_id'] = prefix + "_" + feed.routes['route_id']
        feed.trips['prefixed_route_id'] = prefix + "_" + feed.trips['route_id']
        feed.trips['prefixed_trip_id'] = prefix + "_" + feed.trips['trip_id']
        feed.stop_times['prefixed_trip_id'] = prefix + "_" + feed.stop_times['trip_id']
        feed.stop_times['prefixed_stop_id'] = prefix + "_" + feed.stop_times['stop_id']
        feed.stops['prefixed_stop_id'] = prefix + "_" + feed.stops['stop_id']

        combined_routes = pd.concat([combined_routes, feed.routes], ignore_index=True)
        combined_trips = pd.concat([combined_trips, feed.trips], ignore_index=True)
        combined_stop_times = pd.concat([combined_stop_times, feed.stop_times], ignore_index=True)
        combined_stops = pd.concat([combined_stops, feed.stops], ignore_index=True)

    # Return a GTFSFeed object
    return GTFSFeed(
        routes=combined_routes,
        trips=combined_trips,
        stop_times=combined_stop_times,
        stops=combined_stops
    )

step1 = load_and_combine_gtfs(gtfs_path_2020)

"""# Step #2: Rail, ferry, BRT stops

This step identifies transit stops that serve rail, light rail, subway, ferry, or some BRT routes. These routes-except for BRT-have their own designation
in GTFS files and all count for HQ transit stops. BRT routes are selected by name.
"""

def rail_ferry_brt(feed, mode = maximal):
    """
    Rail, light rail, and ferry stops from GTFS data, including specific LA BRT lines.

    Params:
        feed: Partridge GTFS feed object created above.

    Returns:
        GeoDataFrame with rail, light rail, and ferry stops, and stops for specified LA BRT lines.
    """
    # Define route types for rail, light rail, and ferry services
    if not mode:
        rail_route_types = [0, 1, 5, 7]  # Light rail, subway, cable car, funicular

    else:
        rail_route_types = [0, 1, 2, 5, 7]  # Light rail, subway, intercity rail, cable car, funicular

    ferry_route_type = 4  # Ferry only

    # Filter routes for rail, light rail, and ferry
    rail_ferry_routes = feed.routes[
        feed.routes['route_type'].isin(rail_route_types + [ferry_route_type])
    ]

    # Include specific LA + SF BRT lines by route_long_name
    la_brt_routes = feed.routes[
        feed.routes['route_long_name'].isin(["Metro G Line 901", "Metro J Line 910/950", "GEARY RAPID"])
    ]

    # Combine rail, ferry, and BRT routes
    all_relevant_routes = pd.concat([rail_ferry_routes, la_brt_routes])

    # Ensure 'route_id' matches between routes and trips
    relevant_trips = feed.trips[
        feed.trips['prefixed_route_id'].isin(all_relevant_routes['prefixed_route_id'])
    ]

    # Ensure 'trip_id' matches between trips and stop_times
    relevant_stop_times = feed.stop_times[
        feed.stop_times['prefixed_trip_id'].isin(relevant_trips['prefixed_trip_id'])
    ]

    # Ensure 'stop_id' matches between stop_times and stops
    relevant_stops = feed.stops[
        feed.stops['prefixed_stop_id'].isin(relevant_stop_times['prefixed_stop_id'])
        ]

    # Create GeoDataFrame for spatial analysis
    rail_ferry_brt_gdf = gpd.GeoDataFrame(
        relevant_stops,
        geometry=gpd.points_from_xy(relevant_stops.stop_lon, relevant_stops.stop_lat),
        crs="EPSG:4326"  # Best projection for the area
    )

    print("Rail, ferry, and BRT stops extracted.")
    return rail_ferry_brt_gdf

step2 = rail_ferry_brt(step1)

"""# Step #3: Bus stops with peak hours

This step identifies bus stops with frequent service during peak hours (morning and afternoon). In the maximal definition, a stop qualifies
if it has, from one route, at least one hour-long period with 3 arrivals throughout the morning and afternoon peak hours. This hour-long period need not start at the beginning of an hour; for example, it could stretch from 7:30-8:30AM. In the minimal definition, a stop qualifies if it has, from one route, at least 9 buses arriving during the morning peak AND 12 buses in the afternoon peak. The morning peak is 6-9AM and the afternoon peak is 3-7PM.
"""

def bus_stops_peak_hours(feed, mode = maximal):
    """
    Returns:
        GDF containing bus stops with at least 21 total arrivals during peak hours for at least one route.
    """
    if not mode:
        am_peak_start = pd.to_datetime('06:00:00').time()
        am_peak_end = pd.to_datetime('08:59:59').time()
        pm_peak_start = pd.to_datetime('15:00:00').time()
        pm_peak_end = pd.to_datetime('18:59:59').time()

        # Only buses
        bus_routes = feed.routes[feed.routes['route_type'] == 3]  # Bus route_type = 3

        # Use `route_id` if `prefixed_route_id` is missing for some reason
        route_key = 'prefixed_route_id' if 'prefixed_route_id' in bus_routes.columns else 'route_id'
        trip_key = 'prefixed_trip_id' if 'prefixed_trip_id' in feed.trips.columns else 'trip_id'

        # Bus trips
        bus_trips = feed.trips[feed.trips[route_key].isin(bus_routes[route_key])]

        # Merge trip and route data into stop_times
        stop_times_enriched = feed.stop_times.merge(
            bus_trips[[trip_key, route_key]],
            left_on=trip_key,
            right_on=trip_key,
            how="inner"
        )

        # Convert arrival and departure times from seconds to datetime.time
        stop_times_enriched['arrival_time'] = pd.to_datetime(stop_times_enriched['arrival_time'], unit='s').dt.time
        stop_times_enriched['departure_time'] = pd.to_datetime(stop_times_enriched['departure_time'], unit='s').dt.time

        # Filter stop times for AM and PM peak hours
        am_peak_stop_times = stop_times_enriched[
            (stop_times_enriched['arrival_time'] >= am_peak_start) & (stop_times_enriched['arrival_time'] <= am_peak_end) |
            (stop_times_enriched['departure_time'] >= am_peak_start) & (stop_times_enriched['departure_time'] <= am_peak_end)
        ]

        pm_peak_stop_times = stop_times_enriched[
            (stop_times_enriched['arrival_time'] >= pm_peak_start) & (stop_times_enriched['arrival_time'] <= pm_peak_end) |
            (stop_times_enriched['departure_time'] >= pm_peak_start) & (stop_times_enriched['departure_time'] <= pm_peak_end)
        ]

        # Group by stop_id and route_key for AM and PM peak times
        am_route_stop_counts = am_peak_stop_times.groupby(['prefixed_stop_id', route_key]).size()
        pm_route_stop_counts = pm_peak_stop_times.groupby(['prefixed_stop_id', route_key]).size()

        # Filter for stops meeting thresholds for at least one route
        qualifying_am_stops = am_route_stop_counts[am_route_stop_counts >= 9].reset_index()['prefixed_stop_id']
        qualifying_pm_stops = pm_route_stop_counts[pm_route_stop_counts >= 12].reset_index()['prefixed_stop_id']
        print(len(qualifying_am_stops))
        print(len(qualifying_pm_stops))

        # Identify stops that meet both AM and PM criteria for at least one route
        high_frequency_stops = set(qualifying_am_stops).intersection(set(qualifying_pm_stops))
        print(len(high_frequency_stops))

        # Extract corresponding stops from the stops table
        bus_peak_stops = feed.stops[feed.stops['prefixed_stop_id'].isin(high_frequency_stops)]
        print(len(bus_peak_stops))

        # Convert to GeoDataFrame for spatial analysis
        bus_peak_gdf = gpd.GeoDataFrame(
            bus_peak_stops,
            geometry = gpd.points_from_xy(bus_peak_stops.stop_lon, bus_peak_stops.stop_lat),
            crs = "EPSG:4326"  # Best projection for the area
        )

        print(f"Identified {len(bus_peak_gdf)} high-frequency bus stops meeting route-specific thresholds.")
        return bus_peak_gdf


    else:
        # Define new AM and PM periods
        am_start = pd.to_datetime('00:00:00').time()
        am_end = pd.to_datetime('11:59:59').time()
        pm_start = pd.to_datetime('12:00:00').time()
        pm_end = pd.to_datetime('23:59:59').time()

        # Only buses
        bus_routes = feed.routes[feed.routes['route_type'] == 3]  # Bus route_type = 3

        # Use `route_id` if `prefixed_route_id` is missing
        route_key = 'prefixed_route_id' if 'prefixed_route_id' in bus_routes.columns else 'route_id'
        trip_key = 'prefixed_trip_id' if 'prefixed_trip_id' in feed.trips.columns else 'trip_id'

        # Bus trips
        bus_trips = feed.trips[feed.trips[route_key].isin(bus_routes[route_key])]

        # Merge trip and route data into stop_times
        stop_times_enriched = feed.stop_times.merge(
            bus_trips[[trip_key, route_key]],
            left_on=trip_key,
            right_on=trip_key,
            how="inner"
        )

        # Convert arrival and departure times from seconds to datetime.time
        stop_times_enriched['arrival_time'] = pd.to_datetime(stop_times_enriched['arrival_time'], unit='s').dt.time
        stop_times_enriched['departure_time'] = pd.to_datetime(stop_times_enriched['departure_time'], unit='s').dt.time

        # Function to count arrivals in rolling one-hour windows
        def count_rolling_window(stop_times, start_period, end_period):
            stop_times_filtered = stop_times[
                ((stop_times['arrival_time'] >= start_period) & (stop_times['arrival_time'] <= end_period)) |
                ((stop_times['departure_time'] >= start_period) & (stop_times['departure_time'] <= end_period))
            ]
            # Combine all times for processing
            stop_times_filtered['time'] = pd.to_datetime(
                stop_times_filtered['arrival_time'].astype(str)
            ).dt.floor('T')  # Ensure consistent datetime format for grouping

            # Group by stop, route, and rolling one-hour windows
            stop_times_filtered = stop_times_filtered.sort_values(by='time')
            grouped_counts = stop_times_filtered.groupby(['prefixed_stop_id', route_key])

            qualifying_stops = set()
            for (stop_id, route), group in grouped_counts:
                group = group.set_index('time').resample('1h').size()
                if any(group >= 3):
                    qualifying_stops.add(stop_id)

            return qualifying_stops

        # Apply rolling window logic to AM and PM periods
        qualifying_am_stops = count_rolling_window(stop_times_enriched, am_start, am_end)
        qualifying_pm_stops = count_rolling_window(stop_times_enriched, pm_start, pm_end)

        # Combine qualifying stops for AM and PM
        qualifying_stops = qualifying_am_stops.intersection(qualifying_pm_stops)
        print(f"Number of qualifying stops: {len(qualifying_stops)}")

        # Extract corresponding stops from the stops table
        bus_peak_stops = feed.stops[feed.stops['prefixed_stop_id'].isin(qualifying_stops)]
        print(f"Number of stops in stops table after filtering: {len(bus_peak_stops)}")

        # Convert to GeoDataFrame for spatial analysis
        bus_peak_gdf = gpd.GeoDataFrame(
            bus_peak_stops,
            geometry=gpd.points_from_xy(bus_peak_stops.stop_lon, bus_peak_stops.stop_lat),
            crs="EPSG:4326"  # Best projection for the area
        )

        print(f"Identified {len(bus_peak_gdf)} high-frequency bus stops meeting route-specific thresholds.")
        return bus_peak_gdf

step3 = bus_stops_peak_hours(step1)

"""# Step #4: Bus stop intersections

This step finds bus stops that are near each other (within 150 or 500 feet) but serve different bus routes. This prevents stops on the same route
from intersecting, which Cal-ITP believed was against the intent of the law.
"""

def identify_bus_stop_intersections(feed, bus_peak_gdf, mode = maximal):
    """
    Identifies intersecting bus stops based on a distance threshold, excluding stops on the same route.
    """
    bus_peak_gdf = bus_peak_gdf.to_crs(epsg=4326)

    if not mode:
        distance_threshold = 150

    else:
        distance_threshold = 500

    # Join route information to bus stops by trip_id
    trip_route_data = feed.trips[['trip_id', 'route_id']]
    stop_trip_route_gdf = (
        bus_peak_gdf.merge(feed.stop_times[['stop_id', 'trip_id']], on='stop_id')
        .merge(trip_route_data, on='trip_id')
        .merge(feed.routes[['route_id', 'route_short_name']], on='route_id')  # Join with routes to include route_short_name
        .drop_duplicates(subset=['stop_id', 'route_id'])
    )

    # Convert distance from feet degrees (assuming 1 degree â‰ˆ 364,000 feet, true near-ish to the equator)
    feet_to_degrees = distance_threshold * 0.0000027473

    # Create an R-tree spatial index for faster spatial queries
    spatial_index = stop_trip_route_gdf.sindex

    # List to collect intersecting stop IDs
    intersecting_stops = set()

    # Iterate through each stop and find nearby stops using the spatial index
    for idx, stop_a in stop_trip_route_gdf.iterrows():
        latitude = stop_a.geometry.y
        # Corrects for Earth's roundness
        longitude_correction = np.cos(np.radians(latitude))
        threshold_degrees = feet_to_degrees * longitude_correction

        # Query the spatial index for potential matches within the threshold
        possible_matches_index = list(spatial_index.intersection(stop_a.geometry.buffer(threshold_degrees).bounds))
        possible_matches = stop_trip_route_gdf.iloc[possible_matches_index]

        # Filter for stops on different routes - so same route stops don't trigger
        for _, stop_b in possible_matches.iterrows():
            # Filters by - route_id, route_short_name (first 4 characters only), trip_id, stop_name (first 15 characters only),
            #and stop_id (checks whether stop_id is within 10, meaning they are too close and on same route)
            if stop_a['route_id'] != stop_b['route_id']:
                if str(stop_a['route_short_name'])[:4] != str(stop_b['route_short_name'])[:4]:
                    if stop_a['trip_id'] != stop_b['trip_id']:
                        if stop_a['stop_name'][:15] != stop_b['stop_name'][:15]:
                            # A few stops have text in their stop_id columns, this gets rid of text
                            stop_a['stop_id'] = ''.join(ch for ch in stop_a['stop_id'] if ch.isdigit())
                            stop_b['stop_id'] = ''.join(ch for ch in stop_b['stop_id'] if ch.isdigit())
                            if (int(stop_a['stop_id']) - int(stop_b['stop_id'])) >= abs(10):
                                # Calculate precise distance only for potential matches to save time
                                distance = stop_a.geometry.distance(stop_b.geometry)
                                if distance <= threshold_degrees:
                                    intersecting_stops.update([stop_a['stop_id'], stop_b['stop_id']])

    # Filter original GeoDataFrame based on unique intersecting stops found
    intersecting_stops_gdf = bus_peak_gdf[bus_peak_gdf['stop_id'].isin(intersecting_stops)]

    print(f"Identified {len(intersecting_stops_gdf)} intersecting bus stops within {distance_threshold} feet on different routes.")
    return intersecting_stops_gdf

step4 = identify_bus_stop_intersections(step1, step3)

"""# Step #5: Merge datasets

This step combines the rail/ferry stops and high-quality bus stops (from steps 2 and 4) into one dataset. It then exports this dataset as a shapefile of the stops (without 1/2 mile buffers) to a designated file path.
"""

def merge_transit_stops(rail_ferry_brt, bus_intersections_gdf, mode = maximal,
                        output_path='/Volumes/One_Touch/Transit_Job/Output_Together/2/Max'):
    """
    Merges the rail/ferry, intersecting bus, and high-frequency corridor GDFs
    into a single GDF, export
    """
    # Ensure all GeoDataFrames are in the same CRS
    if rail_ferry_brt.crs != bus_intersections_gdf.crs:
        bus_intersections_gdf = bus_intersections_gdf.to_crs(rail_ferry_brt.crs)

    if not mode:
        distance_threshold = 150

    else:
        distance_threshold = 500

    rail_ferry_brt['qualification'] = 'Rail, Ferry, BRT stop'
    bus_intersections_gdf['qualification'] = f'Bus stop with intersection within {distance_threshold} feet'

    # Step 2: Concatenate GeoDataFrames
    all_high_quality_stops_gdf = gpd.GeoDataFrame(
    pd.concat([rail_ferry_brt, bus_intersections_gdf, #corridor_stops_gdf
              ], ignore_index=True)
    )

    # Aggregate qualifications for duplicate stops
    # Group by stop_id, keeping geometry and combining qualifications as a list
    all_high_quality_stops_aggregated = (
    all_high_quality_stops_gdf
    .groupby('stop_id', as_index=False)
    .agg({
        'qualification': lambda x: '; '.join(set(x)),  # Combine unique qualifications as a single string
        'geometry': 'first',  # Keep the first geometry entry for each stop_id
        'stop_lat': 'first',  # Keep the latitude and longitude
        'stop_lon': 'first',
        'stop_name': 'first' # These are the fields each GTFS is guaranteed to have, using others returns errors

    })
    )

    all_high_quality_stops_aggregated_gdf = gpd.GeoDataFrame(
    all_high_quality_stops_aggregated,
    geometry='geometry',
    crs="EPSG:4326")

    # Export to a shapefile (or other format as needed)
    # Don't forget to comment out if not saving!
    all_high_quality_stops_aggregated_gdf.to_file(f"{output_path}/file2.shp", driver='ESRI Shapefile')

    return all_high_quality_stops_aggregated_gdf

step5 = merge_transit_stops(step2, step4)

"""# Step #6: Buffer transit stops

This step creates a buffer zone (1/2 mile) around each of the transit stops. These are the high-quality transit areas resulting from
the stops. This step exports the buffer zone to a designated file path.
"""

def buffer_transit_stops(high_quality_stops_gdf, buffer_distance_miles = 0.5,
                         output_path='/Volumes/One_Touch/Transit_Job/Output_Together/2/Max'):
    """
    Buffer 1/2 mile around each stop and save to shapefile.
    """
    # Convert buffer distance from miles to meters
    buffer_distance_meters = buffer_distance_miles * 1609.34

    # Use UTM Zone 11N for buffering accuracy (best for buffering, I learned)
    if high_quality_stops_gdf.crs.to_epsg() != 32611:  # UTM Zone 11N
        high_quality_stops_gdf = high_quality_stops_gdf.to_crs(epsg=32611)

    # Apply the buffer and set it as the active geometry
    high_quality_stops_gdf['buffer'] = high_quality_stops_gdf.geometry.buffer(buffer_distance_meters)
    buffered_stops_gdf = high_quality_stops_gdf.set_geometry('buffer').copy()

    # Drop the original geometry to avoid conflicts when saving
    buffered_stops_gdf = buffered_stops_gdf.drop(columns='geometry')

    # Save to file
    # Don't forget to comment out if not saving!
    buffered_stops_gdf.to_file(f"{output_path}/file_buffer2.shp", driver='ESRI Shapefile')

    return buffered_stops_gdf

step6 = buffer_transit_stops(step5)